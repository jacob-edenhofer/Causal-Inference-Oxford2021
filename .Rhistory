# import packages
library(tidyverse)
library(readr)
library(janitor)
# import data and delete first two rows, given they are redundant
nrw22 <- read_delim("https://www.wahlergebnisse.nrw/landtagswahlen/2022/LW22_WK_insgesamt.txt",
delim= ";", skip = 3) %>%
clean_names() %>%
slice(-c(1:2))
# prune dataset to include parties of interest (grune, linke, afd, cdu, spd and fdp) and zweitstimmen
nrw22_pruned <- nrw22 %>%
select(starts_with("wahl"),
grep("gultige_stimmen_z", names(nrw22)),
grep("cdu_z|spd_z|af_d_z|grune_z|die_linke_z|fdp_Z", names(nrw22)))
knitr::opts_chunk$set(echo = TRUE, message=FALSE, warning=FALSE)
bisls <- ivreg(logpgp95 ~ avexpr | logem4, data = ajr)
knitr::opts_chunk$set(echo = TRUE, message=FALSE, warning=FALSE)
# packages
library(readr) # importing csv files
library(haven) # importing dta data files
library(tidyverse) # data wrangling and plotting
library(ggrepel) # adding text labels to graphs
library(kableExtra) # creating tables
library(multiwayvcov) # robust standard errors
library(ivpack) # iv regressions
library(Matching) # matching
library(cobalt) # matching
library(sm) # matching
library(ggeffects) # marginal effects
library(margins) # marginal effects
library(fixest) # fixed effects
library(ggpubr) # saving graphs
library(modelsummary) # regression tables
library(stargazer) # regression tables
library(estimatr) # robust estimation of (linear) models
library(rdd) # rdd
library(rddensity) # rdd
library(rdrobust) # rdd
# data
ajr <- read_dta("Data/AJR.dta")
vietnam <- read_stata("Data/Vietnam_matching.dta")
did_snow <- read_delim("Data/snow_did.csv", delim = ";")
fowler_assembly <- read_stata("Data/StateAssemblyData.dta")
fowler_census <- read_stata("Data/StateCensusData.dta")
broockman <- read_stata("Data/Broockman2009.dta")
audit <- read_delim("Data/audit.csv", delim = ",")
stigma <- read_stata("Data/stigma.dta")
# delete missing values
stigma1 <- stigma %>%
filter(!is.na(stigma))
g1 <- lm(stigma ~ treat + age + female + edu + income, data = stigma1)
ggpredict(g1, terms = "treat")
# education as a factor
stigma1 <- stigma1 %>%
mutate(edu_factor = as.factor(edu))
# regression with interaction
z001 <- lm(stigma ~ treat*edu_factor + income + age + female, data = stigma1)
# plot
plot(ggpredict(z001, terms = c("edu_factor", "treat")), connect.lines = T) +
scale_color_discrete(name = "Treatment Status",
labels = c("Higher-Income Client (Control)",
"Lower-income Client (Treatment)")) +
labs(y = "Predicted Stigma",
title = "Predicted Stigma Across Education and By Treatment Status") +
scale_x_continuous(name = "Education Level",
labels = c("0" = "Less Than Primary", "1" = "Primary",
"2" = "Secondary", "3" = "Post\nsecondary")) +
theme(legend.position = "bottom",
legend.direction = "horizontal")
# income as factor
stigma1 <- stigma1 %>%
mutate(income_factor = as.factor(income))
# regression with interaction
z_income01 <- lm(stigma ~ treat*income_factor + age + edu + female, data = stigma1)
# plot
plot(ggpredict(z_income01, terms = c("income_factor", "treat")), connect.lines = T) +
scale_color_discrete(name = "Treatment Status",
labels = c("High-Income Client (Control)",
"Lower-Income Client (Treatment)")) +
labs(title = "Predicted Stigma Across Income and By Treatment Status", x = "Income",
y = "Predicted Stigma") +
scale_x_continuous(breaks = seq(0, 2, by = 1)) +
theme(legend.position = "bottom",
legend.direction = "horizontal")
# creating truncated binary variable, that is used in Panel B
stigma1 <- stigma1 %>%
mutate(binary_unaccept = case_when(stigma %in% c(4, 5)~"1", TRUE~"0"),
binary_unaccept1 = as.numeric(binary_unaccept))
# given that the dependent variable is binary, I estimate a logit specification.
treat_edu <- glm(binary_unaccept1 ~ treat*edu + age + female + income,
family = binomial(logit), data = stigma1)
# creating a data frame that contains the predicted values
treat_edu.df <- ggpredict(treat_edu, terms = c("edu", "treat"))
# plotting the predicted values gives us Figure 3, Panel B
plot(treat_edu.df) +
scale_color_discrete(name = "",
labels = c("High-Income Client (Control)",
"Lower-Income Client (Treatment)")) +
labs(y = "Predicted Probability",
title = "Predicted Probability of Answering '(Totally) Unacceptable'\nAcross Education Levels and by Experimental Condition\n(Figure 3, Panel B)") +
scale_x_continuous(name = "Education Level",
labels = c("0" = "Less Than Primary", "1" = "Primary",
"2" = "Secondary", "3" = "Post\nsecondary")) +
theme(legend.position = "bottom",
legend.direction = "horizontal")
ggplot(ajr, aes(avexpr, logpgp95)) +
geom_point() +
geom_smooth(method = "lm") +
xlim(3, 10) +
ylim(4, 11) +
geom_text_repel(aes(label = shortnam)) +
labs(x = "Average Protection Against Expropriation Risk (1985-1995)",
y = "Log GDP p.c. Measured in 1995 Dollars",
title = "Association Between Log GDP p.c. and \nAverage Protection Against Expropriation Risk")
ggplot(ajr, aes(logem4, logpgp95)) +
geom_point() +
geom_text_repel(aes(label = shortnam)) +
geom_smooth(method = "lm") +
labs(x = "Logged Settler Mortality",
y = "Log GDP p.c. Measured in 1995 Dollars",
title = "Visualisation of Reduced-Form Equation")
itt <- lm(logpgp95 ~ logem4, data = ajr)
modelsummary(itt, output = "kableExtra",
coef_map = c('(Intercept)' = 'Intercept',
'logem4' = 'Logged Settler Mortality'),
gof_omit = 'AIC|BIC|Log.Lik|Adj')
fstage <- lm(avexpr ~ logem4, data = ajr)
modelsummary(fstage, output = "kableExtra",
coef_map = c('(Intercept)' = 'Intercept',
'logem4' = 'Logged Settler Mortality'),
gof_omit = 'AIC|BIC|Log.Lik|Adj')
# there are more elegant ways to do this; for our purposes, this quick-and-dirty way is sufficient, I dare say
fvcovCl <- cluster.vcov(fstage, ajr$shortnam)
coeftest(fstage, fvcovCl)
coef(summary(itt))["logem4", "Estimate"]/coef(summary(fstage))["logem4", "Estimate"]
bisls <- ivreg(logpgp95 ~ avexpr | logem4, data = ajr)
modelsummary(bisls,
output = "markdown",
gof_omit = 'AIC|BIC|Log.Lik|Adj')
fvcovCl1 <- cluster.vcov(bisls, ajr$shortnam)
coeftest(bisls, fvcovCl1)
# regressions
models_ajr <- list("Model 1" = ivreg(logpgp95 ~ avexpr | logem4, data = ajr),
"Model 2" = ivreg(logpgp95 ~ avexpr + africa | logem4 + africa, data = ajr),
"Model 3" = ivreg(logpgp95 ~ avexpr + africa + lat_abst + asia | logem4 + africa + lat_abst + asia, data = ajr),
"Model 4" = ivreg(logpgp95 ~ avexpr + africa + lat_abst + asia + rich4 | logem4 + africa + lat_abst + asia + rich4, data = ajr))
# table
modelsummary(models_ajr, output = "kableExtra",
gof_omit = 'AIC|BIC|Log.Lik|Adj')
# logit
random <- glm(bombed_969_bin ~ std + ln_dist +
score + lnhpop +  mod2a_1ajul +
mod2a_1admn, family = binomial(logit), data = vietnam)
# plot
ps.df <- data.frame(pr_score = predict(random, type = "response"),
treat = random$model$bombed_969_bin)
ps.df$pr_score  <- fitted(random)
sm.density.compare(ps.df$pr_score, ps.df$treat, xlab="Propensity Score")
title(main="Propensity Scores by Treatment Status")
text(0.2,8, "Control", col="red")
text(0.2,6, "Treated", col="green")
# there are more sophisticated ways of doing this
# match without replacement I
set.seed(27688)
match.without.r.ps <- Match(Y = vietnam$mod2a_1adec, Tr = vietnam$bombed_969_bin,
X = random$fitted.values, estimand = "ATT",
replace = F)
summary(match.without.r.ps)
# match without replacement II
set.seed(88888)
match.without.r.ps.alt <- Match(Y = vietnam$mod2a_1adec, Tr = vietnam$bombed_969_bin,
X = random$fitted.values, estimand = "ATT",
replace = F)
summary(match.without.r.ps.alt)
set.seed(27688)
match.w.r.ps <- Match(Y = vietnam$mod2a_1adec, Tr = vietnam$bombed_969_bin,
X = random$fitted.values, estimand = "ATT",
replace = T)
summary(match.w.r.ps)
# balance plot for without replacement
p1 <- love.plot(bal.tab(match.without.r.ps,
vietnam$bombed_969_bin ~ vietnam$std +
vietnam$ln_dist + vietnam$score + vietnam$lnhpop+  vietnam$mod2a_1ajul + vietnam$mod2a_1admn), stats = "mean.diffs", var.order = "unadjusted", thresholds = .1, abs = T, title = "PSM-NN Without Replacement")
# balance plot for with replacement
p2 <- love.plot(bal.tab(match.w.r.ps,
vietnam$bombed_969_bin ~ vietnam$std +
vietnam$ln_dist + vietnam$score + vietnam$lnhpop+  vietnam$mod2a_1ajul + vietnam$mod2a_1admn), stats = "mean.diffs", var.order = "unadjusted", thresholds = .1, abs = T, title = "PSM-NN With Replacement")
# bind together
ggpubr::ggarrange(p1, p2, nrow = 2)
# without replacement I
set.seed(27688)
match.ps.cal25.without.r <- Match(Y = vietnam$mod2a_1adec, Tr = vietnam$bombed_969_bin, X = random$fitted.values, caliper = 0.25, replace = F)
summary(match.ps.cal25.without.r)
# without replacement II
set.seed(88888)
match.ps.cal25.without.r.alt <- Match(Y = vietnam$mod2a_1adec, Tr = vietnam$bombed_969_bin, X = random$fitted.values, caliper = 0.25, replace = F)
summary(match.ps.cal25.without.r.alt)
set.seed(27688)
match.ps.cal25.w.r <- Match(Y = vietnam$mod2a_1adec, Tr = vietnam$bombed_969_bin, X = random$fitted.values, caliper = 0.25, replace = T)
summary(match.ps.cal25.w.r)
# Caliper without replacemet: Balance check
z1 <- love.plot(bal.tab(match.ps.cal25.without.r,
bombed_969_bin ~ std + ln_dist +
score + lnhpop +  mod2a_1ajul +
mod2a_1admn, data = vietnam),
stat = "mean.diffs",
threshold = .1, var.order = "unadjusted",
abs=T, title = "PSM-NN Caliper Without Replacement")
# Caliper with replacement: Balance check
z2 <- love.plot(bal.tab(match.ps.cal25.w.r,
bombed_969_bin ~ std + ln_dist +
score + lnhpop +  mod2a_1ajul +
mod2a_1admn, data = vietnam),
stat = "mean.diffs",
threshold = .1, var.order = "unadjusted",
abs=T, title = "PSM-NN Caliper With Replacement")
ggarrange(z1, z1, nrow = 2)
precontrol <- mean(did_snow$deaths[did_snow$postperiod==0 & did_snow$treated==0])
precontrol
postcontrol <- mean(did_snow$deaths[did_snow$postperiod==1 & did_snow$treated==0])
postcontrol
pretreat <- mean(did_snow$deaths[did_snow$postperiod==0 & did_snow$treated==1])
pretreat
postreat <- mean(did_snow$deaths[did_snow$postperiod==1 & did_snow$treated==1])
postreat
manual_did <- (postreat-pretreat)-(postcontrol-precontrol)
manual_did
did_robust_interaction <- lm_robust(deaths ~ postperiod*treated,
data = did_snow,
cluster = id)
# table
modelsummary(did_robust_interaction,
output = "markdown",
gof_omit = 'AIC|BIC|Log.Lik|Adj')
fowler_assembly <- fowler_assembly %>%
mutate(compulsory_voting = case_when((state == "Tasmania" & year>=1931)~1,
(state == "Queensland" & year>=1915)~1,
(state == "Victoria" & year>=1927)~1,
(state == "New South Wales" & year>=1930)~1,
(state == "Western Australia" & year>=1939)~1,
(state == "South Australia" & year>=1944)~1,
TRUE ~ 0))
## turnout
reg1 <- lm(turnout ~ compulsory_voting + as.factor(year) +
as.factor(statecode), data = fowler_assembly)
reg1_robust_se <- sqrt(diag(cluster.vcov(reg1,
cluster = fowler_assembly$state)))
## turnout with state-specific trends
reg2 <- lm(turnout ~ compulsory_voting + as.factor(year)
+ as.factor(statecode)*year, data = fowler_assembly)
reg2_robust_se <- sqrt(diag(cluster.vcov(reg2,
cluster = fowler_assembly$state)))
## labor vote share
reg3 <- lm(voteshare ~ compulsory_voting + as.factor(year) +
as.factor(statecode), data = fowler_assembly)
reg3_robust_se <- sqrt(diag(cluster.vcov(reg3,
cluster = fowler_assembly$state)))
## labor vote share with state-specific time trends
reg4 <- lm(voteshare ~ compulsory_voting + as.factor(year) +
as.factor(state)*year, data = fowler_assembly)
reg4_robust_se <- sqrt(diag(cluster.vcov(reg4,
cluster = fowler_assembly$state)))
## labor seat share
reg5 <- lm(seatshare ~ compulsory_voting + as.factor(year) +
as.factor(statecode), data = fowler_assembly)
reg5_robust_se <- sqrt(diag(cluster.vcov(reg5,
cluster = fowler_assembly$state)))
## labor seat share with state-specific trends
reg6 <- lm(seatshare ~ compulsory_voting + as.factor(year) +
as.factor(state)*year, data = fowler_assembly)
reg6_robust_se <- sqrt(diag(cluster.vcov(reg6,
cluster = fowler_assembly$state)))
stargazer(reg1, reg2, reg3, reg4, reg5, reg6, type = "text",
se = list(reg1_robust_se, reg2_robust_se, reg3_robust_se,
reg4_robust_se, reg5_robust_se, reg6_robust_se),
dep.var.labels = c("Turnout", "Labor vote share", "Labor seat share"),
add.lines = c(list(c('State fixed effects', "Yes",
"Yes",
"Yes", "Yes", "Yes",
"Yes")),
list(c('Year fixed effects', "Yes",
"Yes",
"Yes", "Yes", "Yes",
"Yes")),
list(c('State-specific trends',
"", "Yes", "", "Yes", "",
"Yes"))),
omit = c(1911:1950, "2", "3", "4",
"5", "6", "2:year",
"3:year", "4:year", "5:year",
"6:year", "Queensland", "Tasmania",
"South Australia", "Western Australia", "Victoria",
"Queensland:year", "Western Australia:year",
"Victoria:year", "Tasmania:year", "year", "Constant"),
report = ("vcs"),
model.names = F, no.space = T, align = T,
keep.stat = c("rsq", "n", "ser"),
covariate.labels = "Compulsory voting",
header = F, df = F, column.sep.width = "-15pt",
title = "Replication of Table 2 in Fowler",
notes = "Standard errors are clustered at the state level.",
notes.align = "l", notes.append = F)
fowler_census <- fowler_census %>%
mutate(pop = male_pop + female_pop,
ln_pop = log(pop),
share_u_21 = popunder21/pop,
share_married = married/pop,
share_born_australia = borninaustralia/pop,
share_church = churchofengland/pop,
share_manufac = manufacturing/pop,
compulsory_voting = case_when((state == "TAS" & year>=1931)~1,
(state == "QNZ" & year>=1915)~1,
(state == "VIC" & year>=1927)~1,
(state == "NSW" & year>=1930)~1,
(state == "WA" & year>=1939)~1,
(state == "SA" & year>=1944)~1,
TRUE ~ 0))
## lnpop
reg7 <- lm(ln_pop ~ compulsory_voting + as.factor(year) +
as.factor(state), data = fowler_census)
reg7_robust_se <- sqrt(diag(cluster.vcov(reg7,
cluster = fowler_census$state)))
reg7_pvalue <- coeftest(reg7, cluster.vcov(reg7,
cluster = fowler_census$state))[, "Pr(>|t|)"]
## share under 21
reg8 <- lm(share_u_21 ~ compulsory_voting + as.factor(year) +
as.factor(state), data = fowler_census)
reg8_robust_se <- sqrt(diag(cluster.vcov(reg8,
cluster = fowler_census$state)))
reg8_pvalue <- coeftest(reg8, cluster.vcov(reg8,
cluster = fowler_census$state))[, "Pr(>|t|)"]
## share married
reg9 <- lm(share_married ~ compulsory_voting + as.factor(year) +
as.factor(state), data = fowler_census)
reg9_robust_se <- sqrt(diag(cluster.vcov(reg9,
cluster = fowler_census$state)))
reg9_pvalue <- coeftest(reg9, cluster.vcov(reg9,
cluster = fowler_census$state))[, "Pr(>|t|)"]
## share_born_australia
reg10 <- lm(share_born_australia ~ compulsory_voting + as.factor(year) +
as.factor(state), data = fowler_census)
reg10_robust_se <- sqrt(diag(cluster.vcov(reg10,
cluster = fowler_census$state)))
reg10_pvalue <- coeftest(reg10, cluster.vcov(reg10,
cluster = fowler_census$state))[, "Pr(>|t|)"]
## share_church
reg11 <- lm(share_church ~ compulsory_voting + as.factor(year) +
as.factor(state), data = fowler_census)
reg11_robust_se <- sqrt(diag(cluster.vcov(reg11,
cluster = fowler_census$state)))
reg11_pvalue <- coeftest(reg11, cluster.vcov(reg11,
cluster = fowler_census$state))[, "Pr(>|t|)"]
## share_manufac
reg12 <- lm(share_manufac ~ compulsory_voting + as.factor(year) +
as.factor(state), data = fowler_census)
reg12_robust_se <- sqrt(diag(cluster.vcov(reg12,
cluster = fowler_census$state)))
reg12_pvalue <- coeftest(reg12, cluster.vcov(reg12,
cluster = fowler_census$state))[, "Pr(>|t|)"]
stargazer(reg7, reg8, reg9, reg10, reg11, reg12, type = "text",
se = list(reg7_robust_se, reg8_robust_se, reg9_robust_se,
reg10_robust_se, reg11_robust_se, reg12_robust_se),
p = list(reg7_pvalue, reg8_pvalue, reg9_pvalue, reg10_pvalue,
reg11_pvalue, reg12_pvalue),
dep.var.labels = c("ln(Population)", "Under 21", "Married",
"Born in Australia", "Church of England",
"Manufacturing"),
omit = c(1911:1947, "TAS", "QNZ", "VIC",
"NSW", "WA", "SA",
"year", "Constant"), p.auto = F,
t.auto = F, report = c("vcsp"),
model.names = F, no.space = T, align = T,
omit.stat = c("all"),
covariate.labels = "Compulsory voting",
title = "Replication of Table 3 in Fowler",
header = F, column.sep.width = "-5pt",
notes.append = F,
notes = "Standard errors are clustered at the state level.",
notes.align = "l")
rdplot(broockman$dv_c_t2, broockman$dv_c_t1, c = 0,
binselect = "qs", ci=95,
x.label = "Democratic Margin of Victory at t=1",
y.label = "Democratic Margin of Victory at t=2",
title = "Democratic Margin of Victory in Consecutive Congressional Elections")
broockman_pruned <- broockman %>%
filter(dv_c_t1 >= -0.05 & dv_c_t1 <= 0.05) %>%
mutate(treated_broock = ifelse(dv_c_t1 > 0, 1, 0))
rdd_models <- list("Model 1" = lm(dv_c_t2 ~ dv_c_t1 + treated_broock + dv_c_t1*treated_broock, data = broockman_pruned),
"Model 2" = lm(dv_c_t2 ~ dv_c_t1 + I(dv_c_t1^2) + I(dv_c_t1^3) + treated_broock
+ dv_c_t1*treated_broock + I(dv_c_t1^2)*treated_broock
+ I(dv_c_t1^3)*treated_broock,
data = broockman_pruned))
modelsummary(rdd_models,
coef_map = setNames(c("Intercept",
"Dem. vote share (previous election)",
"Treatment dummy",
"Dem. vote share x Treatment",
"Dem. vote share squared",
"Dem. vote share cubed",
"Dem. vote share squared x Treatment",
"Dem. vote share cubed x Treatment"),
c("(Intercept)", "dv_c_t1", "treated_broock", "dv_c_t1*treated_broock",
"I(dv_c_t1^2)", "I(dv_c_t1^3)", "I(dv_c_t1^2):treated_broock", "I(dv_c_t1^3):treated_broock")),
output = "kableExtra",
gof_omit = 'AIC|BIC|Log.Lik|Adj')
h1 <- rdrobust(broockman$dv_c_t2, broockman$dv_c_t1, c=0, p=1,
kernel = "triangular",
h=0.1, cluster = broockman$statesabbrev)
h2 <- rdrobust(broockman$dv_c_t2, broockman$dv_c_t1, c=0, p=1,
kernel = "triangular",
h=0.08, cluster = broockman$statesabbrev)
h3 <- rdrobust(broockman$dv_c_t2, broockman$dv_c_t1, c=0, p=1,
kernel = "triangular",
h=0.06, cluster = broockman$statesabbrev)
h4 <- rdrobust(broockman$dv_c_t2, broockman$dv_c_t1, c=0, p=1,
kernel = "triangular",
h=0.05, cluster = broockman$statesabbrev)
h5 <- rdrobust(broockman$dv_c_t2, broockman$dv_c_t1, c=0, p=1,
kernel = "triangular",
h=0.03, cluster = broockman$statesabbrev)
# matrix
cvs <- matrix(c(0.104, 0.009, 0.074, 0.119, 0.1,
0.102, 0.009, 0.066, 0.115, 0.08,
0.097, 0.010, 0.060, 0.116, 0.06,
0.093, 0.011, 0.062, 0.121, 0.05,
0.094, 0.013, 0.060, 0.131, 0.03),
byrow = T,
nrow = 5, ncol = 5,
dimnames = list(c("h1", "h2", "h3", "h4", "h5"),
c("Coef", "Stde", "lowCI", "upCI", "bandwidth")))
# transform matrix into data frame
rdd3data <- as.data.frame(cvs)
rdd3data$bandwidth <- as.character(rdd3data$bandwidth)
# bandwidth plot
pd <- position_dodge(0.78)
ggplot(rdd3data, aes(bandwidth, Coef, group = bandwidth)) +
geom_point(position=pd) +
geom_errorbar(aes(ymin=lowCI, ymax=upCI,
color=bandwidth), width=.1, position = pd) +
ylim(0,0.2) +
geom_hline(yintercept = 0, linetype = "dashed") +
labs(x = "Bandwidths", y = "Coefficient Estimate",
title = "Bandwidth Sensitivity Plot",
color = "Bandwidth")
incumbency <- rdrobust(broockman$dv_c_t2, broockman$dv_c_t1, c=0, p=1,
kernel = "triangular",
bwselect = "mserd", cluster = broockman$statesabbrev)
summary(incumbency)
DCdensity(broockman$dv_c_t1, c=0, ext.out = F, htest = F)
title(main = "McCrary Density Test", xlab = "Democratic Margin of Victory at t=1",
ylab = "Density")
abline(v=0, lty=1)
rdd_density <- rddensity(broockman$dv_c_t1, c=0)
summary(rdd_density)
densitplot <- rdplotdensity(rdd = rdd_density, broockman$dv_c_t1,
plotRange = c(-0.5, 0.5), plotN = 30,
CIuniform = T)
rdplot(audit$irre.2017, audit$norm.value, c=0, ci=95, binselect = "qs",
x.label = "Norm Value (Running Variable)",
y.label = "Irregularities (2017)",
subset = (audit$norm.value>=-0.2 & audit$norm.value<=0.2))
audit$audit1.2016 <- as.character(audit$audit.2016)
ggplot(subset(audit, norm.value >= -0.2 & norm.value <=0.2), aes(norm.value, irre.2017)) +
geom_point(aes(colour = audit1.2016)) +
geom_smooth(data = filter(subset(audit, subset = (norm.value >= -0.2 & norm.value <=0.2)),
norm.value <= 0), method = "lm") +
geom_smooth(data = filter(subset(audit, subset = (norm.value >= -0.2 & norm.value <=0.2)),
norm.value >= 0), method = "lm") +
geom_vline(xintercept = 0) +
labs(x = "Norm Value", y = "Irregularities (2017)", colour = "Treated")
audit %>%
mutate(audit.2016 = as.character(audit.2016)) %>%
dplyr::group_by(audit.2016, norm.value<=0) %>%
dplyr::summarise(count = n()) %>%
group_by(audit.2016) %>%
mutate(prop = round((count/sum(count))*100, digits = 2)) %>%
kable(col.names = c("Audit 2016", "Norm Value less than or equal to 0", "Count", "Proportion")) %>%
kable_styling(bootstrap_options = "striped")
fuzzy <- rdrobust(audit$irre.2017, audit$norm.value, c = 0,
fuzzy = audit$audit.2016, p=1,
bwselect = "mserd", kernel = "tri")
summary(fuzzy)
bisls <- ivreg(logpgp95 ~ avexpr | logem4, data = ajr)
modelsummary(bisls,
coef_map = c("(Intercept)" = "(Intercept)",
"avexpr" = "Avg. protection against\nexpropriation risk, 1985-1995"),
output = "markdown",
gof_omit = 'AIC|BIC|Log.Lik|Adj')
# regressions
models_ajr <- list("Model 1" = ivreg(logpgp95 ~ avexpr | logem4, data = ajr),
"Model 2" = ivreg(logpgp95 ~ avexpr + africa | logem4 + africa, data = ajr),
"Model 3" = ivreg(logpgp95 ~ avexpr + africa + lat_abst + asia | logem4 + africa + lat_abst + asia, data = ajr),
"Model 4" = ivreg(logpgp95 ~ avexpr + africa + lat_abst + asia + rich4 | logem4 + africa + lat_abst + asia + rich4, data = ajr))
# table
modelsummary(models_ajr, output = "markdown",
gof_omit = 'AIC|BIC|Log.Lik|Adj')
View(ajr)
# regressions
models_ajr <- list("Model 1" = ivreg(logpgp95 ~ avexpr | logem4, data = ajr),
"Model 2" = ivreg(logpgp95 ~ avexpr + africa | logem4 + africa, data = ajr),
"Model 3" = ivreg(logpgp95 ~ avexpr + africa + lat_abst + asia | logem4 + africa + lat_abst + asia, data = ajr),
"Model 4" = ivreg(logpgp95 ~ avexpr + africa + lat_abst + asia + rich4 | logem4 + africa + lat_abst + asia + rich4, data = ajr))
# table
modelsummary(models_ajr,
coef_map = c("(Intercept)" = "(Intercept)",
"avexpr" = "Avg. protection against\nexpropriation risk, 1985-1995",
"lat_abst" = "Latitude",
"africa" = "Africa dummy",
"asia" = "Asia dummy",
"rich4" = "Other continent dummy"),
output = "markdown",
gof_omit = 'AIC|BIC|Log.Lik|Adj')
